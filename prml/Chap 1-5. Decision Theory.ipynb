{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이 장의 목적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 1.2 절에서 확률이론을 사용하여 불확실성에 대해서 어떻게 처리 하는지 수학적 기법을 소개 하였다.\n",
    "   * 결정 이론과 확률론이 결합하여, 불확실성이 포함된 상황에서 최적의 결정을 할 수 있으며, 패턴인식에서 그러한 상황을 만난다.\n",
    "   * 따라서 Decision Theory 에 확률이론이 어떻게 적용하는 기법들에 관해서 논의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 주어진 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 입력벡터 ${\\bf x}$ 와 출력(목표) 벡터 ${\\bf t}$ 를 보자.\n",
    "   * 과제는 새로운 값 ${\\bf x}$ 가 주어질때, ${\\bf t}$ 를 에측 할 수 있는지???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 상화에 따른 과제의 성격"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Regression 문제\n",
    "        * ${\\bf t}$ 는 연속변수에 대한 예측 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분류문제\n",
    "       * ${\\bf t}$ 는 라벨이 될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결합확률분포 $p({\\bf x}, {\\bf t})$ 는ㄴ 이러한 변수들의 불확정성에 대해서 기술을 한다.\n",
    "   * $p({\\bf x}, {\\bf t})$ 를 결정하는 것은 학습 데이타로 부터 추론 하는 것이며, 일반적으로 이책의 많은 부분에서 해법을 제시하는것은 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그러나 실제적인 문제에서, ${\\bf t}$ 에 대해서 구체적인 예측을 할 수 있어야만 하고, 더욱 일반적으로는 ${\\bf t}$ 가 취해야 할 값에 대해 이해한 바탕으로 구체적인 행동을 하여야 한다.\n",
    "   * 이러면이 decision theory 의 주제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 메디컬 진단 예\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * X-ray 사진이 있으며, 사진으로 환자가 암인지 아닌지 판정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 입력 벡터 ${\\bf x}$ 는 이미지에서 픽셀의 강도가 되며, 출력 ${\\bf t}$ 는 암의 존재 여부가 된다.\n",
    "   * 이제 분류를 $\\mathcal C_1$ 을 암이 있는 이미지, $\\mathcal C_2$ 를 암이 없는 이미지 라고 하자.\n",
    "   * ${\\bf t}$ 는 이진값으로 $t = 0$ 는 ${\\mathcal C_1}$ 으로 $t = 1$ 는 ${\\mathcal C_2}$ 로 대응 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이런식으로 라벨링 하는 방법은 확률모델에서 매우 편리한 방법인지는 나중에 보여 줄것이다.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Theory 의 수학적 형태."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 메디컬 진단의 예에서와 같이, 일반적인 추론에 대한 문제는 결합확률분포 $p({\\bf x}, {\\mathcal C}_k)$ 이나 $p({\\bf x}, {\\bf t}) 를 결정하는 문제이다.\n",
    "   * 이런 수학적 형식이 유용하고 유익한 양이 될지라도, 결국에는 환자를 치료해야 할지 말지를 결정해야 하며, 이 결정이 적절한 선택이 되기를 희망한다.\n",
    "   * 이것인 decision step 이며, 주어진 환경에서 최적의 결정을 하는지에 대한 decision theory 의 주제이다.\n",
    "   * 일단 추론문제를 풀고나면 decision stage 는 간단하고 매우 평이하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### decision theory 의 key idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * decision theory 의 이책의 나머지에서 요구하는 주요 아이디어를 소개.\n",
    "   * X-ray 이미지에서 이미지에 연결된 두가지 분류중에 하나를 결정해야 한다.\n",
    "   * 베이지안 이론을 적용한다.\n",
    "$$p(C_k \\mid {\\bf x})=\\dfrac{p({\\bf x}\\mid C_k)p(C_k)}{p({\\bf x})} \\qquad{(1.77)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p(C_k)$ 를 $C_k$ 에 대한 사전확률로 해석하고, $p(C_k \\mid {\\bf x})$ 를 관련있는 사후확률로 해석한다.\n",
    "   * 그러므로, $p(C_1)$ 을 암이 있는 환자의 확률이고, $p(C_1 \\mid {\\bf x})$ 를 X-ray 가 주어진 상황에서 암이 있는 확률이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 목적은 잘못된 분류를 최소화 하는 것이므로, 직관적으로 사후확률이 높은 분류를 갖는 것으로 선택할 것이다.\n",
    "   * 이런 직관이 맞는것이지, 그리고 decision 을 하기 위한 일반적인 조건이 무엇인지 대한 논의를 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 오분류 최소화 (Minimizing the misclassification rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 각 변수 ${\\bf x}$ 에 대해서 가능한 분류 하나씩 대응한다.\n",
    "   * 이것은 입력 변수를 각각 영역 $\\mathcal R_k$ 에 대응시킨다라고 하고, $\\mathcal R_k$ 를 Decision Region 이라고 한다.\n",
    "   * $\\mathcal R_k$ 에 있는 모든 점은 분류 $\\mathcal C_k$ 에 대응된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Decision Region 사이에 있는 경계를 decision boundaries 또는 decision surface 라고 한다.\n",
    "   * 각 decision 영역은 인계될 필요는 없지만, 어떤 분리된 영역을 포함 할 수 있다.\n",
    "   * 이장의 후에, decision region 과 decision boundary 의 예를 만나게 될것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 잘못분류  된 경우 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 최적의 결정을 하기 위해서는 암문제 처럼, 모든 경우를 먼저 고려 하여야 한다.\n",
    "   * 잘못된 결정은 $C_1$ 에 속한 벡터를 $C_2$ 로 분류하거나, 또는 그 반대로 할 경우에 발생한다.\n",
    "   * 이것이 발생활 확률은 다음과 같다.\n",
    " \n",
    " $$p(mistake)=p(x\\in \\mathcal R_1, C_2) + p(x\\in \\mathcal R_2, C_1)=\\int_{\\mathcal R_1}p({\\bf x}, C_2)d{\\bf x} + \\int_{\\mathcal R_2}p({\\bf x}, C_1)d{\\bf x} \\qquad{(1.78)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 $x$ 를 두 클래스 중에 연결하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 각 $x$ 를 두 클래스 중에 하나에 부여는 자유롭게 할 수 있다. 분명하게 $p(mistake)$ 를 최소화 하기 위해서는 각 $x$ 는 식 (1.78) 에서 작은 값을 갖는 클래스에 부여 하여야 한다.\n",
    "   * 따라서 주어진 $x$ 에 대해서 $p({\\bf x}, \\mathcal C_1) \\gt p({\\bf x}, C_2)$ 이면 $x$ 는 class $C_1$ 에 부여 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 확률곱 에 의하여 $p({\\bf x}, C_k) = p(C_k \\mid {\\bf x})\\, p({\\bf x})$ 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p({\\bf x}, \\mathcal C_1) \\gt p({\\bf x}, C_2)$ 는 $p(C_1 \\mid {\\bf x})\\, p({\\bf x}) \\gt p(C_2 \\mid {\\bf x})\\, p({\\bf x})$ 가 되고, 양쪽 항에 공통이 $p({\\bf x})$ 를 제거하면\n",
    "\n",
    "\n",
    "   * 결국 mistake 를 최소화 하는 것은 각 ${\\bf x}$ 를 사후 확률 $p(C_k \\mid {\\bf x}) 가 큰쪽 클래스로 부여하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이런 결과,  단일 변수 x, 두개 클래스에 대해서 그림 1.24 에 표시 되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1.24 x 에 대한 두 클래스 각각에 대한 결합 확률 $p(x, C_k)$ 그래프.\n",
    "   \n",
    "  <img src=\"/files/books/prml/image/1-24joint-prob.png\" width=\"400\" height=\"300\" align=\"left\">\n",
    "  \n",
    "   * 결정경계 $x = {\\hat x}$ 를 포함 $x$ 에 대해 구분된 두 클래스 각각에 대한 결합확률 $p(x, C_k)$ 도식화.\n",
    "   * $x \\geq {\\hat x}$ 는 $C_2$ 로 분류하고, decision region 은 $\\mathcal R_2$ 에 속하게 된다.\n",
    "   * $x \\lt {\\hat x}$ 는 $C_1$ 로 분류하고, decision region 은 $\\mathcal R_1$ 에 속하게 된다.\n",
    "   * 에러는 불루, 그린, 레드 영역에서 발생한다. 즉 $x \\lt {\\hat x}$ 에서 클래스 $C_2$ 가 $C_1$ 로 잘못 분류된다.(레드와 그린이 합친영역)\n",
    "   * 반대로, $x \\geq {\\hat x}$  에서 클래스 $C_1$ 을 $C_2$ 로 잘못 분류된다(불루 영역)\n",
    "   * decision boundary ${\\hat x}$ 가 이동하면, 불루하고 그린이 합쳐진 영역은 변하지 않으나($C_1$ 을 $C_2$ 로 오인), 레드 영역은 변하게 된다.\n",
    "   * ${\\hat x}$ 의 최적의 선택은 곡선 $p(x, C_1)$ 과 $p(x, C_2)$ 가 교차하는 점이고, 이 영역에선  ${\\hat x} = x_0$ 이고 레드 영역이 사라진다.\n",
    "   * 이 점에서 misclassification 비율이 최소가 되는 것과 같다. 그리고 $x$ 의 각 값에 대해서 높은 사후확률 $p(C_k \\mid x)$ 를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스를 K 개로 확장하면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * K 개 클래스의 일반적인 경우, correct 되는 확률을 최대화 하는것은 다음과 같다.\n",
    "  $$p(correct)=\\sum_{k=1}^{K}p(x \\in \\mathcal R_k, \\mathcal C_k) = \\sum_{k=1}^{K}\\int_{\\mathcal R_k}p(x, \\mathcal C_k) d{\\bf x} \\qquad{(1.79)}$$\n",
    "  \n",
    "   * 각 ${\\bf x}$ 가 $p({\\bf x}, C_k)$ 가 최대가 되는 클래스에 부여되는 그런 영역 $R_k$ 에 선택되면, 식 1.79 는 최대가 된다.\n",
    "   * $p({\\bf x}, C_k) = p(C_k \\mid {\\bf x})\\,p({\\bf x})$ 가 되고, $p({\\bf x})$ 가 공통 이면, ${\\bf x}$ 는 사후확률 $p(C_k \\mid {\\bf x})$ 가 최대가 되는 클래스에 부여되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Minimizing the expected loss (기대손실 최소화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 의료 진단 문제고 다시 가서\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 많은 경우 단순히 오분류 수를 최소화 하는 것 보다는 더 복잡하다.\n",
    "   * 의료 진단 문제로 다시 가서\n",
    "   * 만일 만일 암이 아닌 환자가 잘못 진단하여 암으로 진단하면(첫번경우), 결과적으로 환자의 고통과 추가 조사의 필요성이 있을 것이다.\n",
    "   * 반대로, 암환자가 건강한것으로 진단을 내면 결국은 치료부족으로 조기 사망이 될 수도 있다(두번째 경우).\n",
    "   * 그러므로, 두 가지 경우 잘못진단 결과는 크게 다를 수 있다.\n",
    "   * 두번째 경우가 첫번째 경우보다 비용이 더 들어도, 첫번쨰 경우보다 실수를 더 줄이는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이런 문제는 $loss\\,function$ 도입함으로써 형식화 할 수 있다.\n",
    "   * $loss\\,function$ 는 종종 $cost\\,function$ 이라고 한다.\n",
    "   * 이 함수는 가능한 decision 이나 행위를 할때 발생할 손실의 전반적이고 유일한 척도 이다.\n",
    "   * 목적은 발생할 전체적인 손실을 최소화 하는 것입닏다.\n",
    "   * 일부는 $loss\\,function$ 대신에 $utility\\,function$ 을 도입하여 이값이 최대가 되도록 한다.\n",
    "   * $utility$ 가 단순히 $loss$ 를 음수화 한다면, 개념적으로 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loss function 형식화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 새로운 값 ${\\bf x}$ 가 있고, 그것의 진짜 클래스는 $C_k$ 이다.\n",
    "   * 이 ${\\bf x}$ 를 클래스 $C_j$ 에 부여했다. ($j$ 는 반드시 $k$ 와 같을 필요가 없다.)\n",
    "   * 이럴경우 어떤 수준의 손실이 발생하는데 $L_{kj}$ 로 표시 하도록 한다.\n",
    "   * $L_{kj}$ 를 $loss\\,matrix$ (손실행렬) 에서 $k,j$ 요소로 나타난다.\n",
    "   * 암진단 예에서 보면 다음 그림 1-25 형식이 된다.\n",
    " \n",
    " 그림 1-25\n",
    " \n",
    " <img src=\"/files/books/prml/image/1-25loss-matrix.png\" width=\"400\" height=\"300\" align=\"left\">\n",
    "    * row : true class\n",
    "    * column : decision 기준에 의하여 부여된 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-25 에서 보면 correct decirion 이 발생하면 손실은 없다. (암환자는 암 진다, 건강한 사람은 건강한것으로 진단)\n",
    "   * 건강한사람을 암진단하면 1, 암환자를 건강한 사람으로 진단 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loss function 최적화 해법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $loss\\,function$ 을 최소화 하는것이 최적해 이다.\n",
    "   * 입력 벡터 ${\\bf x}$ 가 주어질때고, 진짜 클래스 의 불확정 정도는 결합확률 $p({\\bf x}, \\mathcal C_k)$ 로 표현한다.\n",
    "   * 평균 손실을 최소화 하길 원한다. \n",
    "   * 평균은 다음과 같이 계산한다.\n",
    " \n",
    " $$\\mathbb E[L] = \\sum_{k}\\sum_{j}\\int_{R_j}L_{kj}\\,p({\\bf x}, C_k)\\,d{\\bf x} \\qquad{(1.80)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 각 ${\\bf x}$ 는 독립적으로 decision 영역 $\\mathcal R_j$ 에 부여된다.\n",
    "   * 목적은 식 손실 기대값 1.80 이 최소화 하도록 $R$ 을 선택하는 것이다.\n",
    "   * 식 1.80 에서, ${\\bf x}$ 에 대해서, $\\sum_{k}L_{kj}\\,p({\\bf x}, C_k)$ 를 최소화 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p({\\bf x}, C_k) = p(C_k \\mid {\\bf x})\\,p({\\bf x})$ 를 이용하고, $p({\\bf x})$ 공통을 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 기대손실을 최소화 하는 decision rule 은 각 ${\\bf x}$ 에 대해서 클래스 $j$ 에 부여되는 손실 양은\n",
    "\n",
    "$$\\sum_{k} L_{kj} \\,p(C_k \\mid {\\bf x}) \\qquad({1.81})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 1.81 이 최소화 하는 것이어야 한다.\n",
    "   * 이것은 잘 알다시피, 클래스에 대한 사후 확률을 알면 명백하게 평범한것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 The Reject Option (리젝트 옵션)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분류에러는 사후확율 $p(C_k \\mid {\\bf x})$ 가 1 보다 현저하게 작거나, 또는 결합분포 $p({\\bf x}, C_k)$ 와 유사한 값을 갖는 , 입력 space 영역 에서 발생한다.\n",
    "   * 이런 영역은 클래스에 속할지 불확실한 경우가 있는 영역이다.\n",
    "   * 일부 응용시스템에서는 분류 결정을 해야 하는 경우 낮은 에러를 내기 어려운 경우에 decision 을 하지 않는다. 이러 것을 $rejection\\,option$ 이라고 한단.\n",
    "   * 예를 들어, 의료예제에서, X-ray 이미지에서 의심의 여지가 없는 것은 자동 분류를 하고, 애매한 경우에 전문가에게 넘긴다.\n",
    "   * 이런 경우 임계값 $\\theta$ 를 도입하여, 사후확률 $p(C_k \\mid {\\bf x})$ 의 최대값이 $\\theta$ 보다 작거나 같은 그런 ${\\bf x}$ 에 대해서 reject 할 수 있도록 한다.\n",
    "   \n",
    "   * 그림 1-26에서 단일 연속변수 $x$ , 2가지 클래스에 대해서 설명한다.\n",
    "\n",
    "\n",
    "   * 그림 1-26 reject region\n",
    "   \n",
    "<img src=\"/files/books/prml/image/1-26reject.png\" width=\"400\" height=\"300\" align=\"left\">\n",
    "\n",
    "   * $x$ 에 대해서 사후 확률 이 임계값 $\\theta$ 보다 같거나 작은 경우 reject 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $\\theta = 1$ 이면 모든 경우가 reject 한다.\n",
    "   * $\\theta \\lt \\frac{1}{K}$ 가 있어서 reject 되는 것이 없는 클래스를 K 로 잡는것으로 하여, reject 를 $\\theta$ 에 의해서 조정하게 된다.\n",
    "   * 이것을 reject decision 이 발생할때, 발생할 손실을 반영하여, loss matrix 를 주어지고, expected loss 를 최소화 하는 기준으로 reject 기준을 확장시켜 나갈수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4 Inference and decision (추론 과 결정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분류문제를 두 단계롤 나눈다. 추론단계 (inference stage) 와 decision stage(결정단계)\n",
    "   * 추론 단계에서는 학습데이터로 $p(C_k \\mid {\\bf x})$ 를 결정\n",
    "   * 계속해서 decision stage(결정단계) 에서 사후확률을 이용하여 최적의 클래스를 부여한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 또다른 접근 방법은 두개의 문제를 한꺼번에 해결하고, 간단하게 입력 ${\\bf x}$ 를 decision 에 직접 맵핑 하는 함수를 학습하는 것이다. 이런 함수를 $discriminant\\,function$ (판별함수) 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실제문제에서 decision problems 해결에서 접근방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * decision problems 해결에서 3가지 접근 방식을 정의 할 수 있다. 3가지 다 실제 문제 해결에서 사용한다. 복잡도가 큰것 부터 설명한다.\n",
    "   * 문제는 주어진 ${\\bf x}$ 가 어느 클래스 $C_k$ 에 속하는지 추론하는 방법을 푸는데는 3가지의 접근 방법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 먼저 각 클래스 $C_k$ 에 대한 클래스 조건 밀도를 $p(C_k \\mid {\\bf x})$ 와 사전 확률 $p(C_k)$ 를 구하고 나서 이것을 이용해서 사후 확률 $p(C_k \\mid {\\bf x})$ 를 구한다.\n",
    "   * 베이즈 이론 을 사용하요 사후 확률을 구한다.\n",
    "   $$p(C_k|{\\bf x})=\\dfrac{p({\\bf x}|C_k)p(C_k)}{p({\\bf x})} \\qquad{(1.82)}$$\n",
    "   * 분모 는 다음과 같다.\n",
    "   $$p({\\bf x}) = \\sum_{k} p({\\bf x}) \\mid C_k)\\, p(C_k) \\qquad({1.83})$$\n",
    "   \n",
    "   * 직접 결합확률을 사용하여 구하는 경우도 있다 결합확률은 $p({\\bf x}, C_k)$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 사후 확률을 찿은후에는 decision theory 를 이용하여 각 신규 ${\\bf x}$ 마다 해당되는 클래스를 결정합니다.\n",
    "   * 이런 방법의 입력 에 대한 분포를 가지고 있어서, 그 분포로 부터 샘플링이 가능하기 때문에 generative model 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discriminativie models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 먼저 사후 확률을 $p(C_k \\mid {\\bf x})$ 를 직접 구하고 나서, decision theory 를 이용하여 신규 ${\\bf x}$ 에 대해서 클래스를 찿는다.\n",
    "   * 이런 접근은 사후 확률로서 직접 찿는 모델이라서 discriminative models 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discriminant function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * discriminant function 이라고 불리는 $f(x)$ 를 구한다. 이 함수는 각 입력 $x{\\bf x}$ 에 대해서, 직접 클래스에 매핑 하는 함수 이다.\n",
    "   * 예를 들면, 2 클래스 문제에서, $f(.)$ 는 binary 함수가 될 것이고 $f = 0$ 는 $C_1$ 에, $f = 1$ = $C_2$ 에 직접 설정한다.\n",
    "   * 이 경우에는 확률을 사용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  상대적인 장점들.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ${\\bf x}$ 와 $C_k$ 의 결합 확률이므로, 많이 요구한다.\n",
    "   * 많은 시스템에서, ${\\bf x}$ 는 고차원이므로, $p({\\bf x} \\mid C_k)$ 를 합리적으로 정학하게 구하기 위해서 많은 학습데이터를 요구한다.\n",
    "   * 사전확률 $p(C_K)$ 는 종종 각 클래스의 데이터 포인트의 비로서 추정하기도 한다.\n",
    "   * 이 접근 방법의 장점은 식(1.83) 데이터 $p({\\bf x})$ 의 marginal density 를 구할 수 있다는 것이다.\n",
    "   * 이 방법은 낮은 확율을 갖고, 낮은 정확도의 예측을 하는 신규데이터를 찿아내는데 유용하다. 이것은 outlier detection or nvelty detection 으로 알려져 있다.\n",
    "   * 그러나 단지 분류 결정만 하기에는, 너무 많은 데이터와, 컴퓨터 자원을 사용한다.\n",
    "   * 사후확률 $p(C_k \\mid {\\bf x})$ 를 구하려고 하는데, 결합확률 $p({\\bf, x}, C_k)$ 를 구하려고 많은 자원을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 클래스 조건 확률밀도는 많은 것을 포함하고 있지만, 사후확률에는 별로 영향이 없는 것도 있다.\n",
    "   * 그림 1-27 에 이런 내용을 표시한다.\n",
    "   \n",
    "   * 그림 1-27 클래스 조건 확률과 입력조건 확률 비교\n",
    "   \n",
    "<img src=\"/files/books/prml/image/1-27class-condition.png\" width=\"800\" height=\"300\" align=\"left\">\n",
    "\n",
    "   * 단 변수 $x$ 를 갖는 두 클래스 의 class 조건 확률밀도(왼쪽) 과 대응되는 사후확률밀도 (오른쪽)\n",
    "   * 좌변의 $p(x \\mid C_1)$ 은 푸른색 그래프이고, 우변의 사후확률에 영향을 주지 못한다... 왜??/\n",
    "   * 우변의 녹색 수직선은 $x$ 의 결정경계를 나타내며 거기서 최소 오분류율을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * generative models 과 discriminative models 의 기계학습에서 상대적 장점들을 찿는것에 그리고 그것들을 합치는 방법에 대해서 많은 흥미가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminative function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 아주 간단한 방법은 학습데이터로 부터 discriminative function 을 직접구하는것이다.\n",
    "   * 이 함수는 각 ${\\bf x}$ 에 직접 클래스를 연결한다. 따라서 추론과 결정단계가 하나의 학습문제로 되버린다.\n",
    "   * 그림 1.27 에서 x 가 수직 녹색선을 찿는것과 같다. 즉 오분류의 최소 확률를 주는 결정경계이기 때문이다.\n",
    "   * 그러나, 이 접근 방법은 더이사 사후 확률을 사용하지 않는데, 사후 확률을 사용해야만 하는 강력한 이유들이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사후 확률을 사용해야만 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 리스크 최소화 (Minimizing Risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * loss matrix 가 시간마다 변화는 그런 시스템을 고려하자 (financial system 에서 나타난다)\n",
    "   * 사후 확률을 안다면 1.18을 이용하여 적절하게 risk decision 을 최소화 하는 기준을 시시각각 갱신 할 수 있다.\n",
    "   * discriminative funtion 만 있으면, loss matrix 는 다시 학습데이타로 가서 분류문제를 풀려고 할것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reject Option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 사후 확률이 오분류를 최소화 하는  rejection 기준을 결정하도록 한다. 또한 더해서 일반적으로 rejected data point 에 대한 기대손실을 알려준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compensating for class priors (클래스들의 사전 분포에 대한 보상)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 다시 X-ray 문제로 돌아가서\n",
    "   * 자동 스크린닝 시스템을 의해서, 학습데이터로 사용하기위해서 일반인으로 부터 많은수의 X-ray 이미지를 얻었다고 하자.\n",
    "   * 암 경우는 일반인에 비해서 많지 않으므로, 그러한 데이타를 학습으로 사용한다면, 암 클래스에 너무 적은 빈도 때문에 어려움에 닥칠것이다.\n",
    "   * 예를 들어, 모든 점을 정상 클래스에 부여하는것은 이미 99.9%의 정확도를 가지고 있으며, 이런 상식적인 해를 피하기는 어렵다.\n",
    "   * 또한 많은 데이타 셋트가 아주 적은 수의 암 관련 이미지를 가지고 있기 때문에 학습 알고리즘은 암을 가지고 있는 이미지에 잘 노출이 되지 않아서, 일반화가 잘 되지 않는다.\n",
    "   * 각 클래스에 같은수의 균형잡힌 데이터 셋트가 더 정확한 모델을 구현 할 수 있다.\n",
    "   * 이 경우에는 수정된 효과를 학습데이터에 반영하여야만 한다.\n",
    "   * 수정된 학습데이터를 사용하고, 사후확률에 대한 모델을 알고 있다면, \n",
    "   * 베이즈 이론 1.82 에 의해서, 사후확률은 사전확률에 비례하고 있으며, 각 클래스에 대한 데이터 점들의 비율 로서 해석 될 수 있다.\n",
    "   * 따라서, 인위적인 균형잡힌 데이터로 부터 얻은 사후확률을 얻을수 있으므로 (단지 카운팅으로 가능),\n",
    "   * 먼저 데이터를 클래스 비율로 나눈다음\n",
    "   * 모델에 적용하기 위한 전체수에 클래스 비를 곱해준다.\n",
    "   * 마지막으로 전체 사후 확율 합이 1이 되도록 정규화한다.\n",
    "   * 이과정은 사후확률 성질을 이용하는 대신에 직접 discriminative function 을 훈련한다면 적용할수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 복잡한 시스템에서, 각 분리된 모듈에서 담당하도록 문제를 여러 하부 문제로 나누기를 원한다.\n",
    "   * 예를 들면, 의료진단 문제에서, X-ray 이미지 이외에, 혈액 테스트 정보를 가지고 있다.\n",
    "   * 그럼 이질적인 정보를 모두 모아 한꺼번에 하기 보다는 각각 X-ray 이미지 를 담당하고, 다른것은 혈액정보를 담당하게 함으로써 효과적으로 모델을 구성 할 수 있다.\n",
    "   * 2 모델의 각각이 클래스별로 사후확률을 주면, 확률의 법칙을 사용하여 확률을 합칠수 있다.\n",
    "   * 간단한 방법은 다음과 같다.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 확률을 합치는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 입력자료를 X-ray 이미지는 ${\\bf x}_I$, 혈액정보는 ${\\bf x}_B$ 는 독립적이다고 하면\n",
    "\n",
    "$$p({\\bf x}_I, {\\bf x}_B \\mid C_k) = p({\\bf x}_I \\mid C_k)\\,p({\\bf x}_B \\mid C_k) \\qquad({1.84})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 사후확률은 다음과 같이 된다.\n",
    "  \n",
    "  $$\\begin{align} p(C_k \\mid {\\bf x}_I, {\\bf x}_B) \\propto p({\\bf x}_I, {\\bf x}_B \\mid C_k)\\,p(C_k) \\\\\\\\ \\propto p({\\bf x}_I \\mid C_k)\\,p({\\bf x}_B \\mid C_k)\\,p(C_k) \\\\\\\\ \\propto \\dfrac{p(C_k \\mid {\\bf x}_I)\\,p(C_k \\mid {\\bf x}_B)}{p(C_k)} \\end{align} \\qquad{(1.85)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 사전확률 $p(C_k)$ 가 필요하며, 클래스에서 데이터 포인트의 비율로 부터 추정할 수 있다. 그런다음, 전체합이 1이 되도록 정규화 한다.\n",
    "   * 1.84 가정은 naive Bayes model 에서 적용 할 것이다.\n",
    "   * 결합확률 $p({\\bf x}_I, {\\bf x}_B)$ 는 일반적으로 이 모델에서는 factorize 되지 않는다.\n",
    "   * 이것은 마지막장에서 조건부 독립가정 1.84를 요구하지 않는 데이타 결합하는 모델에 대해서 논의 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.5 Loss function for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분류 문제에 대해서 decision theory 를 논의 하였다.\n",
    "   * 다시 앞에서 논의하였던 커브피팅에 대해서 regression problems 로 다시 논의 한다.\n",
    "   * decision stage 는 각 입력 변수 ${\\bf x}$ 에서 값 $t$ 의 추정함수 $y({\\bf x})$를 선택하는 것을 포함한다.\n",
    "   \n",
    "   * 손실함수 $L(t, y({\\bf x}))$ 라고 하면\n",
    "   * 손실 평균 또는 기대값은 다음과 같이 한다.\n",
    "   \n",
    "   $$\\mathbb E[L] = \\iint L(t, y({\\bf x}))p({\\bf x}, t)\\,d{\\bf x}dt \\qquad{(1.86)}$$\n",
    "   \n",
    "   * 앞에서 논의한 sum-of-square 대신에 loss function 을 사용하였다.\n",
    "   * sum-of-square 경우에는 최소가 되는 w 를 구하였는데, 여기서는 그냥 함수 y를 변수로 갖는 범함수(functional) 로 정의 하였다.\n",
    "   * 따라서 $L$ 은 $y$ 의 함수이므로 $L$ 이 최소가 되는 함수 $y$ 의 형태를 묻게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 회귀문제에서 손실함수의 일반적은 것은 다음과 같이 제곱 손실형태로 주어진다.\n",
    "   * $L(t, y({\\bf x})) = \\left \\{ y({\\bf x}) - t \\right \\}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기대손실의 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 기대 손실은 손실함수가 주어진 형태에서 다음과 같이 된다.\n",
    "   \n",
    "   $$ \\mathbb E[L] = \\iint \\left \\{y({\\bf x})-t \\right \\}^2 p({\\bf x}, t)\\,d{\\bf x}dt \\qquad{(1.87)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 우리목적은 $\\mathbb E[L]$ 을 최소화 하는 함수 $y$ 를 선택하는것이다. $\\mathbb E[L]$ 은 범함수 (functional) 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 변분원리를 적용하여\n",
    "\n",
    "$$\\dfrac{\\delta \\mathbb E[L]}{\\delta y({\\bf x})}=2\\,\\int\\left \\{y({\\bf x})-t\\right \\}\\,p({\\bf x}, t)\\,dt=0 \\qquad{(1.88)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $y({\\bf x})$ 에 대해서 풀어보면\n",
    "   \n",
    "$$y({\\bf x})= \\dfrac{\\int t\\,p({\\bf x}, t)\\,dt}{p({\\bf x})}=\\int t\\,p(t \\mid {\\bf x})dt=\\mathbb E_t[t \\mid {\\bf x}] \\qquad{(1.89)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이것은 ${\\bf x}$ 가 주어진 에서 $t$ 의 평균값을 구하는 것이고, regression function 으로 알려져 있다.\n",
    "   * 이것은 그림 1.28 에 표시되어 있다.\n",
    "   \n",
    "   * 그림 1-28 regression function $y(x)$\n",
    "   \n",
    "   <img src=\"/files/books/prml/image/1-28regression.png\" width=\"400\" height=\"300\" align=\"left\">\n",
    "   \n",
    "   * 조건 확률 분포 $p(t \\mid x)$ 가 주어진 상태에서, expected squared loss 를 최소화 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 다변량 타켓 변수 인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $t$ 를 다변량으로 확장하면, t 는 벡터가 된다. ${\\bf t} $\n",
    "   * 이 경우 최적해는 ${\\bf y}({\\bf x}) = \\mathbb E_t[{\\bf t} \\mid {\\bf x}]$ 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최적해를 구하는 다른방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 위 결과를 조금 다른 방법으로 유도함. 회귀문제에 대한 기본성질을 밝힐것이다.\n",
    "   * 조건 기대치에 대한 최적해에 대한 풀이 방법을 생각해서,\n",
    "   * 1.87 의 적분안에 있는 제곱항을 다음과 같이 전개한다.\n",
    " \n",
    " $$\\left\\{y({\\bf x})-t\\right\\}^2 = \\left\\{y({\\bf x})-\\mathbb E[t\\mid{\\bf x}]+\\mathbb E[t\\mid{\\bf x}]-t\\right\\}^2\\\\ = \\left \\{y({\\bf x})-\\mathbb E[t\\mid {\\bf x}] \\right \\}^2 + 2\\left \\{y({\\bf x})-\\mathbb E[t\\mid {\\bf x}] \\right \\}\\left\\{\\mathbb E[t\\mid {\\bf x}]-t\\right \\}+ \\left \\{\\mathbb E[t\\mid {\\bf x}]-t \\right \\}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 표기를 깔끔하기 하기 위해서, $\\mathbb E_t[t \\mid {\\bf x}]$ 를 $\\mathbb E[t \\mid {\\bf x}]$ 로 표시 할 것이다. (1.89 참조)\n",
    "   * $y({\\bf x})$ 는 예측할려고 하는 값이며, 모델에 의해서 결정된다.\n",
    "   * 식 1.89 를 참조하면, $\\mathbb E[t \\mid {\\bf x}]$ 는 t 의 평균값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이 식을 1.87 에서 loss function 에 넣고 t 로 적분하면 cross-term 은 없어지고 ( 없어지게 적당히 $\\mathbb E[t \\mid {\\bf x}]$ 를 잡는다), 다음과 같은 형태로 된다.\n",
    "\n",
    "$$\\mathbb E[L] = \\int \\left\\{y({\\bf x})- \\mathbb E[t\\mid{\\bf x}]\\right\\}^2 p({\\bf x})\\, d{\\bf x} + \\int \\left\\{\\mathbb E[t \\mid {\\bf x}]- t \\right\\}^2 p({\\bf x})\\,d{\\bf x} \\qquad{(1.90)}$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 1.90 의 두번째 항은 $\\int var[t\\mid {\\bf x}]\\,p({\\bf x})\\,d{\\bf x} $ 과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 첫번째 항 에서 $y({\\bf x})$ 는 우리가 찿을려고 하는 식이며, $\\mathbb E[L]$ 이 최소화 하려면 0 이 되어야 한다.\n",
    "   * 따라서 $\\mathbb E[L] = \\mathbb E[t \\mid {\\bf x}]$ 가 된다.\n",
    "   * 이것은 단순히 이전에 유도한 결과와 같고, least square predictor 최적해는 바로 조건부 평균과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 두번째 항은 바로 ${\\bf x}$ 에서 평균된 분포 $t$ 의 분산(variance) 이다.\n",
    "* 이것은 타겟데이터의 기본적인 변동에 대한 것이며, 노이즈로 해석이 가능하다.\n",
    "* 두번째 항은 $y({\\bf x})$ 와 관계가 없기 때문에 loss function 의 최소값에는 관계가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### regression 문제를 푸는 3가지 접근 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분류 문제 처럼, regression 에서도 적절한 확률분포를 찿아야만 한다. 그런 다음 최적의 결정을 하거나 또는 직접 decision 할 수 있도록 모델을 구성하여야 한다. regression 문제를 푸는데 역시 3가지 접근 방법을 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $({\\bf a})$ 결합확률 $p({\\bf x}, t)$ 를 결정하는 추론 문제를 해결 하고, 다음 조건 확률 $p(t \\mid {\\bf x})$ 를 구하여, 다음 1.89 주어진 조건 평균을 구하기 위하여 maginalized 한다.\n",
    "   \n",
    "   * $({\\bf b})$ 먼저 조건 확률분포 $p(t \\mid {\\bf x})$ 를 결정하기 위한 추론 문제를 해결 하고, 다음 1.89 를 구하기 위해서 marginalize 한다\n",
    "   \n",
    "   * $({\\bf c})$ 학습데이타로 부터 직접 regression function $y({\\bf x})$ 를 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 3 가지 접근 방법에 대한 상대적인 장점은 앞서 분류 문제에서 와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * squired loss 는 regression 의 loss 함수를 구하는 유일한 방법은 아니다.\n",
    "   * 사실, squired loss 가 나쁜 결과를 가져오는 경우에는 우린 더 현명한 접근방법을 발전 시켜야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### multimodal 분포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 조건 확율 분포에서 발생하는 중요한 예제는 inverse problem 문제를 해결하는데서 나타나듯이 조건 확률 분포 $p(t \\mid {\\bf x})$ 가 멀티모달이라는 것이다 (분포에서 peak 가 여러가 나타나는 경우).\n",
    "   * Minkowski loss 라고 불리는 squred loss 의 일반화 시킨 경우를 보면\n",
    "\n",
    "$$\\mathbb E[L_q] = \\iint \\left|y({\\bf x})-t\\right|^q p({\\bf x}, t) d{\\bf x}dt \\qquad{(1.91)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $q = 2$ 일때, expected loss 가 된다.\n",
    "   * 함수 $\\left |y - t \\right |^q$ 가 q 에 관한 $y - t$ 에 대한 그래프가 그림 1.29 에 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1.29 $L_q = \\left |y - t\\right |^q$ 의 q 에 따른 그래프\n",
    "   \n",
    " <img src=\"/files/books/prml/image/1-29minkowski.png\" width=\"800\" height=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $\\mathbb E[L_q]$ 를 최소는 $q = 2$ 에서 contitional mean 이고, $q = 1$ 와 $q \\to 0$ 에서 conditional median 이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

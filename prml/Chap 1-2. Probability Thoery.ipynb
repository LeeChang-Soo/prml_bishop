{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1-2 확률 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 패턴인식에서 중요한 개념은 불확실성(uncertainty) 의 확률에 대한 것이다.\n",
    "   * 축정에서 노이즈에 대한 처리 및 데이터 세트의 한계에 대한 처리 때문에 확률이론 사용\n",
    "   * 확률이론은 불확실성을 처리및 계량화의 방법을 제공하므로 패턴인식에서 가장 중심적인 기초이다.\n",
    "   * 결정이론 (Decision Theory) 와 결합하여 (1,5절) 정보가 부족하거나, 애매모호해도 가장 최적의 결정을 할 수 있도록 제공함.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 간단한 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 간단하 예제를 통한 기본 개념 소개\n",
    "   * 그림 1-9 2개의 컬러 박스 및 각 박스안의 그린 및 오렌지 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/1-9box.png\" width=\"400\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 2개의 박스 레드 , 불루\n",
    "   * 레드 박스에는 2개 애플 6개 오렌지 있음\n",
    "   * 불루 박스에는 3개 애플 1개 오렌지 있음\n",
    "   * 임의 한 박스를 선택하고, 그 박스에서 임의로 1개의 과일을 선택한다. 그리고 다시 선택된 과일을 다시 원래의 박스에 넣었는지 관찰.\n",
    "   * 이런 과정을 계속 반복한다.\n",
    "   * 레드 박스 선택은 40% 불루박스는 60%, 그리고 선택한 과일을 다시 박스에 넣지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $B$ : 박스 선택 랜덤 변수, $\\left \\{ r, b \\right \\}$, r: red box, b: blue box\n",
    "   * $F$ : 과일 선택 랜덤 변수, $\\left \\{ a, o \\right \\}$, a: apple, o: orange\n",
    "   * 박스를 선택할 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(B=r)=4/10$$\n",
    "$$p(B=b)=6/10$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 기타 확률에 관련된 여러가지 질문들\n",
    "      * 애플을 선택할 확률\n",
    "      * 오렌지를 선택할 확률\n",
    "      * 기타 등등..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum, Product Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 1-10\n",
    "\n",
    "<img src=\"./image/1-10rules.png\" width=\"400\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 두개의 랜덤 변수 $X$, $Y$ (각각 박스와 과일)\n",
    "   * $X$  value $x_i$, $i = 1,...,M$\n",
    "   * $Y$  value $y_j$, $j = 1,...,L$\n",
    "   * total $N$ trials (시도)\n",
    "   * $X = x_i$ and $Y = y_j$ trial 을 $n_{i,j}$\n",
    "   * $X = x_i$ 에서 trials 횟수를 $c_i$\n",
    "   * $Y = u_j$ 에서 trials 횟수를 $r_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결합확률 (Joint Probability)\n",
    "\n",
    "##### Sum Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-10 참조 바람\n",
    "   * __Sum rule__ 또는 __Marginal probability__\n",
    "\n",
    "   * $X = x_i \\, and \\, Y = y_j$ 에서 발생한 확률을 $p(X = x_i, Y = y_j)$ 라고 표시 하고 결합확률이라고 함.\n",
    "   \n",
    "   $$p(X=x_i, Y=y_j)=\\dfrac{n_{ij}}{N} \\qquad{(1.5)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $X$ 가 $x_i$ 를 선택할 확률을 $P(X = x_i)$ 라고 하면\n",
    "\n",
    "    $$p(X=x_i)=\\dfrac{c_i}{N} \\qquad{(1.6)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-10 에서 컬럼 $i$ 번째 경우의 수는 그 컬럼에서 모든 셀의 합에 있는 경우의 수이므로 $c_i = \\sum_{j}{n_{ij}}$ 이다.\n",
    "   * 그러므로 (1.5) 와 (1.6) 에서\n",
    "\n",
    "$$p(X=x_i)=\\sum_{j=1}^{L}{p(X=x_i, Y=y_j)} \\qquad{(1.7)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 (1.7)을 __Sum rule__ 이라고 하며, $P(X = x_i)$ 를 __Marginal Probability__ 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Product Rule\n",
    "\n",
    "   * Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $X = x_i$ 가 주어진 경우에 $Y = yj$ 가 발생할 경우를 $p(Y=y_j|X=x_i)$ 라고 표시 한다\n",
    "   * $X = x_i$ 가 주어긴 경우 $Y = y_j$ 의 조건부 확률 (Conditional Probability) 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(Y=y_j\\mid X=x_i)=\\dfrac{n_{ij}}{c_i} \\qquad{(1.8)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * (1.5) (1.6) (1.8) 에서\n",
    "\n",
    "$$p(X=x_i, Y=y_j)=\\dfrac{n_{ij}}{N} = \\dfrac{n_{ij}}{c_i} \\dfrac{c_i}{N}=p(Y=y_j|X=x_i)p(X=x_i) \\qquad{(1.9)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 간단한 형식으로 표현 하면\n",
    "\n",
    "   * sum rule\n",
    "   \n",
    "   $$p(X) = \\sum_Y p(X,Y) \\qquad{(1.10)}$$\n",
    "   \n",
    "   * Product rule\n",
    "   \n",
    "   $$p(X,Y)=p(Y\\mid X)\\,p(X) \\qquad{(1.11)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * $P(X, Y)$ = $p(Y, X)$ 대칭성 관계를 이용하여 베이즈 정리는 \n",
    "  \n",
    "  $$p(Y|X)=\\dfrac{p(X\\mid Y)p(Y)}{p(X)} \\qquad{(1.12)}$$\n",
    "  \n",
    "  * 베이즈 정리에서 분자는 \n",
    "  \n",
    "  $$p(X)=\\sum_Y{p(X\\mid Y)p(Y)} \\qquad{(1.13)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 1-11 두 변수 $X$, $Y$ 관련한 도감.\n",
    "\n",
    "<img src=\"./image/1-11conditional-prob.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-11 은 두 랜덤 변수 $X \\, and \\, Y$ 와 그 관련 해서 결합분포, 조건부 분포, 마지널 분포 관련 설명이다.\n",
    "   * $N = 60$ data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다시 처음의 예제로 돌아가서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 박스를 선택할 확률은 각각\n",
    "\n",
    "$$p(B=r)=4/10 \\qquad{(1.14)}$$\n",
    "\n",
    "$$p(B=b)=6/10 \\qquad{(1.15)}$$\n",
    "\n",
    "   * $P(B = r) + P(B = b) = 1$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 불루박스를 선택한 경우에 그 박스에서 애플을 선택하는 경우 확률은 3/4 이다. $p(F = a \\mid B = b)$ = 3/4 로 표시한다.\n",
    "   * 모두 4가지 경우의 조건부 확률은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(F=a \\mid B=r)=1/4 \\qquad(1.16)$$\n",
    "\n",
    "$$p(F=o \\mid B=r)=3/4 \\qquad(1.17)$$\n",
    "\n",
    "$$p(F=a \\mid B=b)=3/4 \\qquad(1.18)$$\n",
    "\n",
    "$$p(F=o \\mid B=b)=1/4 \\qquad(1.19)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 모든 확률은 normalized 되어야 하므로 \n",
    "   \n",
    "$$p(F=a|B=r) + p(F=o|B=r) = 1 \\qquad{(1.20)}$$\n",
    "\n",
    "$$p(F=a|B=b) + p(F=o|B=r) = 1 \\qquad{(1.21)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * sum 과 product probability 공식을 이용하여 apple 를 선택할 확률은\n",
    "\n",
    "$$p(F = a) = p(F = a\\mid B = r)p(B = r) + p(F = a\\mid B = b)p(B = b) = \\frac{1}{4} \\times \\frac{4}{10} + \\frac{3}{4} \\times \\frac{6}{10} = \\frac{11}{20} \\qquad{(1.12)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 따라서 $p(F = o) = 1 - \\frac{11}{20} = \\frac{9}{20}$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 선택 되어진 과일이 오렌지 일 경우 red 또는 blue 박스에 나온 확률은 얼마일까?\n",
    "   \n",
    "   * red 박스인 경우\n",
    "\n",
    " $$p(B = r|F = o) = \\dfrac{p(F = o|B = r)p(B = r)}{p(F = o)} = \\frac{3}{4} \\times \\frac{4}{10} \\times \\frac{20}{9} = \\frac{2}{3} \\qquad(1.23)$$\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * blue 박스인 경우는 $p(B=b|F=o) = 1 - \\frac{2}{3} = \\frac{1}{3}$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이즈 이론의 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 선택된 과일의 정체를 말하기 전에 어떤 박스를 선택했는지에 대해서 질문을 받으면, 제공 할 수 있는 정보는 선택된 박스의 확률 $P(B)$ 이다.\n",
    "   * 이것을 사전확률 $prior \\, probability$ 이라고 한다.\n",
    "   * 과일의 정보를 알기 전에 이미 어느 박스에서인지를 알수 있기 때문이다.\n",
    "   * 일단 과일이 오렌지 라는 정보를 알고 있다면, 베이즈 이론에 의하여 $p(B|F)$ 를 계산 할 수 있다.\n",
    "   * 이것을 사후확률 $posterior\\,probability$ 라고 한다. \n",
    "   * 이것은 관측된 F 정보를 얻은 후에 얻는 확률이기 때무이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 우리의 예제에서\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * red 박스를 선택할 사전 확률은 4/10 이다.\n",
    "   * 따라서 red 박스 보다는 blue 박스를 선택할 경향이 더 크다고 한다. (6/10)\n",
    "   * 그러나 일단 과일이 오렌지라는 정보를 알면 red box 를 선택할 확률은 2/3 이 된다. \n",
    "   * 이것을 사후 확률이라고 한다. 이 경우에는 red box 를 선택할 경향이 더 크다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 독립확률\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p(X,Y) = p(X)p(Y)$ 이면 확률변수 X, Y 를 독립이라고 한다.\n",
    "   \n",
    "   \n",
    "   * 독립인 경우 Product rule 에 따라서 $p(Y \\mid X) = p(Y)$ 가 된다.\n",
    "   \n",
    "   \n",
    "   * $p(X,Y) = p(Y \\mid X)p(X) = p(X)p(Y)$ 이다.\n",
    "   \n",
    "   \n",
    "   * 또한 $p(Y\\mid X) = p(Y) \\to p(Y \\mid X)p(X) = p(X)p(Y)$ 가 되므로\n",
    "   \n",
    "   \n",
    "   * $p(Y\\mid X) = p(Y)$ 이면 독립 이다.\n",
    "   \n",
    "   \n",
    "   * $p(X,Y) \\equiv p(X \\cap B)$ 이므로 \n",
    "   \n",
    "   \n",
    "   * $p(X \\cup Y) = p(X) + p(Y) - p(X \\cap Y)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 확률밀도 (Probability densities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이산적인 사건의 연속 대신에 연속 확률 변수를 고려 해 본다.\n",
    "   * 엄밀한 전개보다는 직관적이고 개념적인 것에서 논의를 시작한다.\n",
    "   * 실 확률 변수 $x$ 가 $(x, x + \\delta x)$ 에 있을 확률을 $\\delta x \\to 0$ 에서 $p(x)\\delta x$ 라고 한다.\n",
    "   * 이때 $p(x)$ 를 x 에서 $probability \\, density$ 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 따라서 구간 $(a, b)$ 에서 확률은 \n",
    "  \n",
    "  $$p(x \\in (a, b)) = \\int_{a}^{b}p(x)dx \\qquad{(1.24)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-12 연속 확률변수 에 대한 개념 그래프\n",
    "\n",
    "<img src=\"./image/1-12continuous.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 확률은 항상 0 보다 커야 하므로 $x$ 는 반드시 실수 상에 있어야 하므로 확률밀도 $p(x)$ 는 다음 조건을 만족하여야 한다.\n",
    "   \n",
    "$$p(x)\\ge 0 \\qquad{(1.25)}$$\n",
    "\n",
    "$$\\int{p(x)dx}=1 \\qquad{(1.26)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 확률밀도 함수의 확률변수 변경일 경우에는 jacobian factor 를 곱해야 한다.\n",
    "   * $x = g(y)$ 로 변경한다면, $f(x) \\to \\tilde{f(y)} = f(g(y))$  이다.\n",
    "   * 확률밀도 함수 $p_x(x)$ 를 새로운 변수 $y$ 에 관련하여 $p_y(y)$ 로 표시 한다면\n",
    "   * 구간 $(x, x + \\delta x)$ 에 있는 관측은 구간 $(y, y + \\delta y)$ 에서 변경되며\n",
    "   * $p_x(x)\\delta x \\simeq p_y(y) \\delta y$ 로 되며\n",
    "\n",
    "$$p_y(y)=p_x(x)\\left|\\dfrac{dx}{dy}\\right|=p_x(g(y))\\left|g'(y)\\right| \\qquad{(1.27)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누적분포함수 $cumulative \\, distribution function$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 구간 $(- \\infty, z)$ 에서 누적분포함수는 \n",
    "   \n",
    "   $$P(z) = \\int_{-\\infty}^{z} p(x)dx\\qquad{(1.28)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 따라서 $P'(x) = p(x)$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다변량 확률 밀도 변수 $multivariate \\, probability \\, density$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 여러 연속변수 $x_1,...,x_D$ 를 고려하면 벡터 형식으로는 $\\bf x$ 라 한다.\n",
    "   * $p(\\bf x) = p(x_1,...,p_D)$ 로 표시 할 수 있다.\n",
    "   * 구간 $(\\bf x, \\bf x + \\delta \\bf x)$ 에서 확률밀도함수 는 $p(\\bf x) \\delta \\bf x$ 가 되면 다음 성질을 만족한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p({\\bf x}) \\ge 0 \\qquad{(1.29)}$$\n",
    "\n",
    "$$\\int p({\\bf x}) d{\\bf x} = 1 \\qquad{(1.30)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 변수 $x$ 가 이산 변수 이면 확률밀도함수 $probability \\, mass \\, function$ 이라고 한다.\n",
    "   \n",
    "   * 연속변수 인 경우에도 sum, product rule 이 같은 방식으로 적용된다.\n",
    "   \n",
    "$$p(x)=\\int{p(x,y)dy} \\qquad{(1.31)}$$\n",
    "\n",
    "$$p(x,y)=p(y|x)p(x) \\qquad{(1.32)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이에 대한 증명은 Measure theory 를 이용하여야 하며, 이책의 범위를 넘어간다.\n",
    "   * 그러나 개념적으로 설명한다면\n",
    "   * 연속 실수를 구간 $\\Delta$ 로 나누어서 각 구간의 대표값으로 활률밀도함수를 구하고, \n",
    "   * 구간 $\\Delta \\to 0$ 로 하여 sum 을 적분구간으로 변경하면 원하는 결과 증명이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 기대값 과 공분산 (Expectations and Covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 기대값: 확률분포 $p(x)$ 상에서 임의 함수 $f(x)$ 의 평균을 기대값이라고 하며 다음과 같이 표현한다.\n",
    "   \n",
    "$$\\mathbb E[f]=\\sum_x{p(x)f(x)} \\qquad{(1.33)}$$\n",
    "\n",
    "$$\\mathbb E[f]=\\int{ {p(x)f(x)} dx} \\qquad{(1.34)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 유한개의 $N$ 을 확률분포 상에서 주어진다면, 기대값은 다음과 같이 근사 된다.\n",
    "   \n",
    "$$\\mathbb E[f]\\simeq\\dfrac{1}{N}\\sum_{n=1}^{N}{f(x_n)} \\qquad{(1.35)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * (1.35)는 Chapter 11 에서 sampling 방법론을 이야기 할때 다시 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다변수 에 대한 처리 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 다 변수를 고려 하는 경우에는 첨자를 이용하여 어떤 확률변수에서 평균을 구하는것인지 구분하도록 한다.\n",
    "   \n",
    "   $$\\mathbb E_x[f(x,y)] \\qquad{(1.36)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 이 경우에는 $f(x,y)$ 의 x 에 대한 편균을 구한것이 되며, 당연히 $E_x[f(x,y)]$ 는 $y$ 의 함수가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조건 함수에 대한 기대갑및 공분산\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 조건 확률에 대한 기대값 역시 같은 형식으로 정의 한다.\n",
    "   \n",
    " $$\\mathbb E_x[f|y]=\\sum_x{p(x|y)f(x)} \\qquad{(1.37)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분산은 다음과 같다.\n",
    "   \n",
    "$$var[f]=\\mathbb E[(f(x)-\\mathbb E[f(x)])]^2 \\qquad{(1.38)}$$\n",
    "\n",
    "   * 이식을 전개 하면\n",
    "$$var[f]=\\mathbb E[f(x)^2]-\\mathbb E[f(x)]^2 \\qquad{(1.39)}$$\n",
    "\n",
    "   * 이식은 $f$ 대신에 $x$ 로 나타낼수도 있는데\n",
    "$$var[x]=\\mathbb E[x^2]-\\mathbb E[x]^2 \\qquad{(1.40)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2개 확률변수를 고려 하는 경우 (공분산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 2개의 확률변수 $x \\, and y$ 에 대해서 공분산은 다음과 같이 정의 한다.\n",
    "   \n",
    "$$cov[x,y] = \\mathbb E_{x,y}[\\left\\{x - \\mathbb E[x]\\right\\}\\left\\{y - \\mathbb E[y]\\right\\}] = \\mathbb E_{x,y}[xy] - \\mathbb E[x]\\mathbb E[y]\\qquad(1.41)$$\n",
    "\n",
    "   * 두 변수 $x$, $y$ 가 같이 변한는 것을 반영한다. 변수 $x,y$ 가 독립적이면 공변항 $\\mathbb E_{x,y}[xy]$ 는 0 이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2개의 확률 변수를 벡터로 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 두 확률변수가 벡터 ${\\bf x} \\, and \\, {\\bf y}$ 로 표현 한다면\n",
    "   \n",
    "$$cov[{\\bf x,y}]= \\mathbb E_{\\bf x,y}[\\left\\{{\\bf x} - E[{\\bf x}] \\right\\} \\left\\{{\\bf y}^T - \\mathbb E[{\\bf y}^T]\\right\\}] = \\mathbb E_{\\bf x,y}[] - \\mathbb E[{\\bf x}]\\mathbb E[{\\bf y}^T]\\qquad(1.42)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 벡터 {\\bf x} 하나로 벡터를 나타낸다면, $cov[{\\bf x}] \\equiv cov[{\\bf x,x}]$ 로 간단한 표현이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 베이지안 확률 (Bayesian probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 지금 까지 확률을 확률변수의 반복적인 빈도수로 표현 하였으며, 이것을 빈도론자(frequentist) 또는 고전통계학이라고 한다.\n",
    "   * 이제 좀더 일반적인 베이지안 관점- 불확실성에 대한 양을 확률로서 표현하는- 에 대해서 알아보자.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 불확실한 사건들, 예를 들면, 달이 태양궤도를 돈다든지, 남극의 얼음표면이 세기말에 없어지든지, 이런 사건은 전에 예를 들던 상자속의 과일에 대한 반복적인 확률과는 다른 것입니다. 그럼에도 불구하고, 예를들면 극지방 어름이 얼마나 빨리 녹는지에 대한 일반적인 아이디어를 가질 수는 있습니다. 우리가 새로운 증거를 예를 들면 인공위성을 이용하여 진단 정보를 얻는다면, 우리는 얼음이 녹는 비율 이라든지, 우리의 의견을 수정해야 할지도 모릅니다. 그런 평가는 우리가 해야 할 행동에 영향을 줍니다. 예를 들면 온실가스 감소로서 우리가 처한 위험에 대한 대처 등입니다. 그런 환경에서 불확실한 정도를 계량화하려고 할 것이며, 새로운 증거에 따라 불확실성을 계속 수정해 나갈 것입니다.  그리고 이예 따른 최적의 행동을 하거나 또는 최적의 결정을 할 것 입니다. 이런점이 확률에 대한 베이지안 해석입니다. 빈도론에서는 오직 발생한 사건에 대해서만 해석을 하지만 베이지안은 비록 발생하지 않아도 발생할 가능성에 대한 증거가 있으면 그것에 대한 확률로 불확실성을 계량화하여 그예 따른 적절한 결론을 낸다.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그러나 불확실성을 표현하기 위하여 확률을 사용하는 것이 일시적인 선택이 아닐지라도, 합리적인 일관된 추론을 하는 것을 그것을 상식으로 존중한다면 그렇게 확률을 사용하는것은 불가피 한 점이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 예를 들어 Cox(1946) 는 만일 수치를 사용하여 신념의 정도를 나타낸다면, 그런한 신념의 상식속성을 인코딩하는 몇몇의 간단한 공리들로서 신념의 정도를 계산하는, 확률의 곱과 합에 대한 연산들, 일련의 유일한 규칙 집합들을 만들어 낼 수 있음을 보였다. 이것은 확률이론이 불확실성을 포함하는 상황에 불대수를 확장으로서 간주 될 수 있음을 보여주는 첫번째 엄밀한 증명이었다. (Jaynes, 2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이후 많은 논문들이 그러한 불확실성의 측도로서 여러 공리들을 제안했다. 모두 각각의 경우에 확률의 규칙에 따른 결과들은 정확하게 행동되었다. 따라서, 베이지안 확률로써 이러한 양을 언급하는 매우 자연스러운 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 패턴인식 분야에서도 역시 확률에 대한 더욱 일반적인 의견을 같는것이 매우 도움이 된다. 예를 들면, 1.1 절에서 논의한 커브 피팅에 대한 다항식의 예제를 보자. 관측값 $t_n$ 에 대한 랜덤 값에 대한 확률을 빈도론자의 관점으로 적용하는 것이 타당 한것처럼 보인다. 그러나 모델 파라미터 ${\\bf w}$ 를 선택하는데 불확성성 정도를 정량화 하기를 원한다. 또한 베이지안 관점에서 보면 모델 파라미터 ${\\bf w}$ 나 모델 자체의 선택에 있어서 기계적인 확률론을 사용 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베이즈 정리는 새로운 의미를 얻게 합니다. 과일 선택의 예제를 생각해보면, 과일의 정보에 대한 관측을 제공하는 것이 red box 를 선택하는 확률을 변경하는 관련된 정보를 제공합니다. 이 예제에서, 베이즈 정리는 사전확률 정보를 가지고 관측된 정보에 따라서 제공된 증거를 포함한 사후확률로 변경하도록 합니다. 후에 자세히 언급하겠지만, 비숫한 접근 방법이 커브피팅예에서, 파라미터 ${\\bf w}$ 를 양으로써 추론하는데 사용 할 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 관측이전에 ${\\bf w}$ 에 대한 정보를 사전확률분포 정보 $p({\\bf w})$ 의 형태로 가정으로서 선택한다.\n",
    "      * 이후 관측된 데이타 $\\mathfrak D = \\left \\{t_1,...,t_N\\right\\}$ 는 조건 확률로서 표현된다.\n",
    "      * 조건 확률은 $P(\\mathfrak D|{\\bf w})$ 로서 표현된다.\n",
    "      * 1.2.5 절에서 베이즈 정리에 의하야 다음과 같이 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p({\\bf w}\\mid \\mathfrak D) = \\dfrac{p(\\mathfrak D \\mid {\\bf w})\\,p({\\bf w})}{p(\\mathfrak D)} \\qquad{(1.43)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그런 다음에 관측된 $\\mathfrak D$ 후에 ${\\bf w}$ 의 불확실성을 사후확률 $p({\\bf w}\\mid \\mathfrak D)$ 형태로 계산하도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p({\\mathfrak D}\\mid {\\bf w})$ 를 $likelihood\\,function$ 이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ posterior \\propto likelihood \\times prior \\qquad{(1.44)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1.43) 에서 분모 는 다음과 같다.\n",
    "\n",
    "$$p(\\mathfrak D)=\\int{p(\\mathfrak D \\mid {\\bf w})\\,p({\\bf w})\\,d{\\bf w}} \\qquad{(1.45)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베이지안 이나 빈도론자 모두에게 우도함수 (likelihood function)  $p(\\mathfrak D| {\\bf w})$ 은 매우 중요한 역할을 한다. 그러나 접근 방법에 있어서는 근본적인 차이가 있다. 빈도론자에게는 ${\\bf w}$ 가 고정된 파라미터 로 생각하며, 그 값은 어떤 추정량 형태로 결정되며, 이 추정량에 대한 에러는 가능한 데이터 셋트 $\\mathfrak D$ 의 가능한 분포를 고려하여야만 얻을수 있다고 본다. (MLE Maximum Likelihood Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 반대로 베이지안에서는 단지 하나의 데이터 셋트 $\\mathfrak D$ (즉 실제로 관측된) 가 있으며, 파라미터의 불확정성은 ${\\bf w}$ 의 확률적 분포 로서 표현된다고 본다. (MAP: Maximum Posterior Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 계속교재를 진행하기 전에 좀더 이해를 위해서.....빈도론자의 주장 예 (MLE: Maximum Likelihood Estimation 최대우도추정량)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 시행으로 부터 경험 (압정 던지기)  $\\to$ 문일철 교수 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 다섯번의 시행\n",
    "     * 3번은 위 (H)\n",
    "     * 2번은 아래 (T)\n",
    "     * 발생 순서는 H,H,T,H,T\n",
    "     * w = 3/5 (?) why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 관찰된 결과가 나올수 있는 파라미터 ${\\bf w}$ 는 무엇일까? $\\to$ 최대 우도 추정량에 의한 설정\n",
    "       * $p(\\mathfrak D\\mid {\\bf w})$ 가 최대가 되도록 ${\\bf w}$ 를 결정한다.\n",
    "       * ${\\mathfrak D}$ 관측값은 5번 시행 했을때 $\\left\\{ H, H, T, H, T \\right \\}$ 로 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 이항분포 (Binomial Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이산 확률 분포\n",
    "     * N 번의 독립적인 시행, yes/no 실험\n",
    "     * 각 성공은 ${\\bf w}$ 의 확률을 가지고 있음.\n",
    "     * 베르누이 실헝으로도 불림(Bernoulli Experiment)\n",
    "   * $p(H) = w$\n",
    "   * $p(T) = 1 - w$\n",
    "   * $p(H,H,T,H,T) = ww(1-w)w(1-w) = w^3(1-w)^2$\n",
    "   * 시행수 $N = 5$\n",
    "   * $k = a_H = 3$\n",
    "   * $p(\\mathfrak D \\mid {\\bf w}) = w^{a_H}(1-w)^{a_T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 최대우도추정 (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 관측 결과로 부터 $p(\\mathfrak D \\mid {\\bf w})$ 가 최대값을 갖도록 w 를 선택\n",
    "   * 이때 $w$ 를 $\\hat w$ 라고 하면\n",
    "   * ${\\hat w} = argmax_w\\, p(\\mathfrak D \\mid {\\bf w})$ 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MLE 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ${\\hat w} = argmax_w\\, p(\\mathfrak D \\mid w) = argmax_w\\,w^{a_H}(1 - w)^{a_T}$\n",
    "   * 최대값이 되는 w 를 구하기 위하여 MLE 의 ln 값을 선택해서 최대 값을 구한다.\n",
    "   * ${\\hat w} = argmax_w \\ln p(\\mathfrak D \\mid w) = argmax_w \\ln \\left \\{ w^{a_H}(1 - w)^{a_T} \\right\\} = argmax_w \\left \\{ a_H \\ln w + a_T \\ln (1 - w) \\right \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 최대값을 구하기 위해 미분이 0 이 되는 w 를 구한다.\n",
    "      * $\\frac{\\mathrm d}{\\mathrm d w} \\big(a_H \\ln w + a_T \\ln (1 - w)) = 0 \\big)$\n",
    "      * $\\dfrac{a_H}{w} - \\dfrac{a_T}{1 - w} = 0$\n",
    "      * $w = \\dfrac{a_H}{a_T + a_H}$\n",
    "      * $w$ 는 $dfrac{a_H}{a_T + a_H}$ 일때 MLE 에서 보면 가장 베스트 후보가 된다.\n",
    "      * 그 $w$ 를 $\\hat w$ = $\\dfrac{a_H}{a_T + a_H}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 얼마큼 시행해야 에러를 줄일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 만일 5번 시행에 모두 H,H,H,H,H 가 나오면???  잘못된 결과 도출\n",
    "   * MLE 의 단점.\n",
    "   * 최소한 몇번을 시행하여 결과를 얻어야 할까??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Simple Error Bound\n",
    "     * $w^*$ 를 에러 영역 $\\epsilon > 0$ 에서 $w$ 라고 하면\n",
    "     * $p(|\\hat w - w^*| \\geq \\epsilon) \\leq 2e^{-2N\\epsilon^2}$\n",
    "     * Hoeffding's inequality 이라고 함. 이 정리를 이용하여 적절한 에러 범위내에서 시행횟수를 구한다.\n",
    "  * PAC (Probably Approximate Correct) learning\n",
    "     * 0.01 % 이내에서 $\\epsilon = 0.01$ 를 구하기 위한 시행 횟수 계산.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이지안의 주장 (최대 사후 추정량 MAP : Maximum a Posteriori Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 다시 압정의 문제로 가서 (MLE 관점에서 본다면)\n",
    "   * 관측값이 압정 위가 3번 아래가 2번 나왔으므로 MLE 에 의해서 위가 나올 확률은 60% 이다.\n",
    "   * 이것을 $\\hat w = \\dfrac{a_H}{a_T + a_H}$ 이다\n",
    "   * 따라서 빈도론자에 따르면, 위로 나올 확률을 선택 하면 승률이 높다.\n",
    "   * 그러나...\n",
    "       * 우리는 50 vs 50 으로 직관적으로 생각하고 있지 않나요?????\n",
    "   * 관측된 데이터 셋트 $\\mathfrak D = \\left \\{H,H,T,H,T \\right \\}$ 에서 불확정한 ${\\bf w}$ 의 분포중에 최대인 $\\hat {\\bf w}$ 는 무엇일까 ??? 베이지안 주장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 베이지안 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p({\\bf w}\\mid \\mathfrak D) = \\dfrac{p(\\mathfrak D \\mid {\\bf w})p({\\bf w})}{p(\\mathfrak D)}$\n",
    "   * $Posterior = \\dfrac{Likelihood \\times Prior\\,Knowledge}{Normalizing Constant}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 주어진 조건에서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p(w \\mid \\mathfrak D) \\propto p(\\mathfrak D \\mid w) p(w)$\n",
    "   \n",
    "      * $p(\\mathfrak D \\mid w) = w^{a_H}(1 - w)^{a_T}$ \n",
    "      \n",
    "      * 그러나 $p(w)$ 는 사전분포로 어떤것일까????\n",
    "      * 베타분포를 이용한다.\n",
    "      \n",
    "   \n",
    "   * MAP 에서는 $w$ 를 다음에서 구한다.\n",
    "       * ${\\hat w} = \\operatorname*{argmax}_w p({\\bf w} \\mid \\mathfrak D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 베타분포 (Beta Distribution) 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베타 분포는 $[0,1]$ 에서 분포하는것으로 확률분포에 많이 사용함.\n",
    "   * $p(w) = \\dfrac{w^{\\alpha - 1}(1 - w)^{\\beta - 1}}{B(\\alpha, \\beta)}$\n",
    "   \n",
    "      * $B(\\alpha, \\beta) = \\dfrac{\\Gamma({\\alpha})\\Gamma({\\beta})}{\\Gamma(\\alpha + \\beta)}$\n",
    "      \n",
    "      * $\\Gamma(\\alpha) = (\\alpha - 1)!$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 따라서 MAP 계산을 해보면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $p(w \\mid \\mathfrak D) \\propto p(\\mathfrak D \\mid w)p(w) \\propto w^{a_H}(1 - w)^{a_T}w^{\\alpha - 1}(1 - w)^{\\beta - 1} = w^{a_H + \\alpha - 1}(1 - w)^{a_T + \\beta - 1}$\n",
    "   \n",
    "   \n",
    "   * 최대화 w 는 이전 MLE 공식에서와 같은 방식으로 적용하면 되므로.. 같은 형식임.\n",
    "   \n",
    "   * $\\hat w = \\dfrac{a_H + \\alpha - 1}{a_H + \\alpha + a_T + \\beta - 2}$\n",
    "   \n",
    "   * 시행수가 늘어나면 MAP 는 MLE 에 유사하게 갈 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 다시 교재로 돌아와서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 빈도론자들이 가장 많이 사용하는것이 최대우도추정($maximum\\,likelihood\\,estimate$) 이다.\n",
    "      * $\\bf w$ 는 $p(\\mathfrak D\\mid\\bf w)$ 가 죄대가 되도록 결정된다.\n",
    "      * 즉 관측된 데이터 $\\mathfrak D$ 가 최대가 되는 $\\bf w$ 를 선택하는 것이라고 볼 수도 있다.\n",
    "      * 기계학습에서는 $error\\,function$ 이라 부르며 보통 likelihood function 의 negative log 형태로 사용한다.\n",
    "         * negative log 함수는 단순 감소 함수이므로 최대우도는 에러를 최소화 하는것같 같다.\n",
    "      * 빈도론자들이 사용하는 방법중 하나가  boostrap 기법이다. \n",
    "         * 제한된 데이터 셋트를 이용하여 여러 데이터 셋트를 생성하는 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 부스트랩(Boostrap)\n",
    "     * $N$ 데이터 포인트를 갖는 원 데이터 셋트를 ${\\bf X} = \\left \\{x_1,...,x_N \\right \\}$ 라고 한다.\n",
    "     * ${\\bf X}$ 에서 임의적으로 $N$ 개의 데이터를 가지고 와서 별도의 데이터 셋트 ${\\bf X}_B$ 를 만든다.\n",
    "        * ${\\bf X}_B$ 는 ${\\bf X}$ 에서 일부는 중복된 데이터가 있으며, 일부는 없는것도 있게 된다.\n",
    "     * 이 과정을 $L$ 번 반복하여 모두 $L$ 개의 크기가 $N$ 인 데이터 셋트가 만들어 진다.\n",
    "     * 파라미터 추정의 통계적인 정확성은 서로 다른 부스트랩 데이터셋트 사이의 예측의 변동성을 조사하면서 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베이지안 관점의 장점\n",
    "      * 사전정보를 포함한다.\n",
    "      * 예를 들어 동전 던지기를 3번 시행하는데, 모두 동전앞면이 나온다면 최대우도추정은 동전앞면이 1이 될 것이다.\n",
    "      * 따라서 앞으로 던질 모든 동전도 앞면이 나올것으로 추정하게 된다.\n",
    "      * 그러나 베이지안 관점에서는 사전에 동전 앞면이 나오는 것은 알고 있으므로 동전앞면이 1이 되는 것을 막을 수 있게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 빈도론자와 베이지안 접근법 관련해서 상대적인 장점관련해서 많은 논란이 있어왔다.\n",
    "   * 그러나 절대적인 빈도론자나 베이지안은 없을 것이다.\n",
    "   * 예를 들면, 베이지안 접근에 대한 공통적인 비판은 사전분포 선택을 주관적인 신념에 의한 것이라기 보다는 수학적 편의성에 기반을 두고 선택한다는 것이다.\n",
    "      * 심지어 사전의 의존성을 통환 결론의 주관적인 성질도 문제의 어려움 처럼 보인다.\n",
    "   * 산전에 대한 의존성을 줄이고하 해서, 소위 $noninformative$ prior 의 동기가 된는것도 있다.\n",
    "   * 그러나 이러한 것은 다른 모델들을 비교할때 어려움에 봉착하게 되며, 실은 사전에 대한 빈약한 선택에 기반을 둔 베이지안 방법은 아주 나쁜 결과를 얻게 된다.\n",
    "   * 빈도론자들이 사용하는 평가방법들이 때론 이러한 문제를 해결 하게 준다.\n",
    "      * 그리고 cross-validation 과 같은 기법은 여전이 모델간 비교에서 여전히 유용하게 남아있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이책은 베이지안 관점을 매우 강조 한다. 그리고 빈도론자들이 요구하는 개념들을 논의 하고, 과거 몇년간 실제적으로 성장한 중요한 베이지안 기법들을 반영 할 것이다.\n",
    "   * 비론 베이지안 기법이 18세기에 시작하였으나, 방법론 적용은 수행하는데 어려운 제약때문에 아주 오랜 시간이 걸려왔다.\n",
    "      * 특히 전체 파라미터 공간에서 maginalized 하는 것이라든지 - 이런것은 모델들을 비교하거나 예측을 하는데 요구되는 필요한 계산들이다 - 등에 만은 제약이 있다.\n",
    "   * MCMC (Markov chain Monte Carlo - 13장) 같은 샘플링 기법은 컴퓨터의 계산이나 용량에서 드라마틱한 개선을 이루어 내어, 베이시안 기법을 사용하는데 새로운 도약이 되고 있다.\n",
    "   * Monte Carlo 방법은 매우 유연하고, 다양한 범위의 모델에 사용할 수 있다.\n",
    "   * 그러나 그런것들은 여전히 계산 집약적이어서 주로 적은 범위 문제에만 사용되어 왔다.\n",
    "   * 최근의 발전은\n",
    "      * variational Bayes(변분베이즈) 와 같은 매우 효율적인 deterministic approximation scheme 나 \n",
    "      * expectation propagation 같은 것이 개발되었다.\n",
    "      * 10 장에서 논의 할 것이다.\n",
    "      * 이런것들은 샘플링 방법에 대해서 보완적인 것을 제공하고, 또한 베이지안 기법을 매우 큰 시스템에 사용 할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 정규분포 (The Gaussian distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 제 2장에서 여러 확률분포와 그들의 성질에 대해서 다를것이다.\n",
    "   * 그러나 정규분포 또는 가우시안 분포 라고 불리는 연속변수에서 확률분포는 여기서 소개한다.\n",
    "   * 이것은 1장 나머지 와 이책 전반에 대해서 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 단일 실변수 $x$ 에 대한 가우시안 분포는 다음과 같다.\n",
    "   \n",
    "   $$\\mathcal N(x \\mid \\mu, \\sigma^2)=\\dfrac{1}{(2\\pi\\sigma^2)^{1/2}}\\exp\\left\\{-\\dfrac{1}{2\\sigma^2}(x-\\mu)^2\\right\\} \\qquad{(1.46)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 2개의 파라미터(모수, parameters)\n",
    "      * $\\mu$ : 평균\n",
    "      * $\\sigma^2$ : 분산\n",
    "   * $\\sigma$ : 표준편차\n",
    "   * $\\beta = \\dfrac{1}{\\sigma^2}$ : 정밀도 (Precision)\n",
    "   \n",
    "   \n",
    "   \n",
    "   * 그림 1.13 가우시안 분포\n",
    "   \n",
    " <img src=\"./image/1-13gaussian.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 (1.46) 가우시안 분포는 다음을 만족해야 한다.\n",
    "   \n",
    "   $$\\mathcal N(x \\mid \\mu, \\sigma^2)\\gt0 \\qquad{(1.47)}$$\n",
    "   \n",
    "   $$\\int_{-\\infty}^{\\infty}\\mathcal N(x \\mid \\mu, \\sigma^2) dx=1 \\qquad{(1.48)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이외 가우시안 분포는 다음과 같은 성질이 있다.\n",
    "      \n",
    "$$\\mathbb E[x]=\\int_{-\\infty}^{\\infty}\\mathcal N(x \\mid \\mu, \\sigma^2){\\cdot}x\\,dx=\\mu \\qquad{(1.49)}$$\n",
    "\n",
    "$$\\mathbb E[x^2]=\\int_{-\\infty}^{\\infty}\\mathcal N(x \\mid \\mu, \\sigma^2){\\cdot}x^2\\,dx=\\mu^2+\\sigma^2 \\qquad{(1.50)}$$\n",
    "\n",
    "$$var[x]=\\mathbb E[x^2]-\\mathbb E[x]^2=\\sigma^2 \\qquad{(1.51)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * D-차원 연속변수 벡터 ${\\bf x} 에 대한 가우시안 분포\n",
    "\n",
    "$$\\mathcal N({\\bf x} \\mid {\\pmb \\mu}, {\\pmb \\Sigma})= \\dfrac{1}{(2\\pi)^{D/2}}\\dfrac{1}{{|\\pmb \\Sigma|}^{1/2}}\\exp\\left\\{-\\dfrac{1}{2}({\\bf x} - {\\pmb \\mu})^T{\\pmb \\Sigma}^{-1}({\\bf x} - {\\pmb \\mu}) \\right\\} \\qquad{(1.52)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ${\\pmb \\mu}$ : D-차원 벡터 평균 (mean)\n",
    "   * $D \\times D$ matrix ${\\pmb \\Sigma}$ : 공분산 (Covariance)\n",
    "   * $\\left|{\\pmb \\Sigma}\\right|$ : ${\\pmb \\Sigma}$ 의 행렬값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 다변량 정규분포는 2.3절에서 자세히 다루지만, 그전에 간단하게 사용해볼 것이다.\n",
    "   \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <img src=\"./image/1-14gaussian-distribution.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "   * 관찰 데이터 셋트 ${\\bf x} = (x_1,...,x_N)$ 이 주어졌다.\n",
    "   * 이것은 N 개의 스칼라 변수 $x$ 를 나타낸다.\n",
    "   * 관측은 독립적인 시행의 결과 가우시안 분포 형태로 데이타는 얻어지고, 이 데이터를 이용하여 평균 $\\mu$ 와 분산 $\\sigma^2$ 을 결정하려고 합니다.\n",
    "   * i.i.d (independent and identically distributed) : 이런식으로 같은 분포에서 독립적으로 얻어지는 데이터 포인트들\n",
    "   * 독립시행일 경우 결합 확률은 각자 확률의 곱으로 표현 할 수 있다. 따라서\n",
    "   * 데이터 셋트 ${\\bf x}$ 가 i.i.d 이므로 관찰데이타 ${\\bf x}$ 는 다음과 같이 표현된다.\n",
    "\n",
    "$$p({\\bf x} \\mid \\mu, \\sigma^2)=\\prod_{n=1}^{N}{\\mathcal N(x_n \\mid \\mu, \\sigma^2)} \\qquad{(1.53)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * $\\mu\\, and\\,\\sigma^2$ 함수로 보면, $p({\\bf x} \\mid \\mu, \\sigma^2)$ 는 가우시안 분포 형태의 likekihood 함수이며 그림 1.14 와 같다.\n",
    "   * 공통적인 주제는 관측된 데이터로 부터 확률분포의 파라미터(모수)를 찿는 것은 likekihood 함수를 최대화 하는 파라미터(모수)를 찿는 것이다.\n",
    "   * 이전에 논의되어온 확률론에서처럼, 주어진 파라미터 (모수)에서 데이터의 확률을 찿는 것이 아니고, 주어진 데이터에서 파라미터(모수)의 확률을 최대화하는 것이 더 자연스럽기 때문에 이상한 기준처럼 보일수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 우도 함수 식 (1.53)을 최대로 하는 $\\mu$ 와 $\\sigma^2$ 를 결정함에 있어서 실제적인 문제에서는 우도 함수의 log를 최대화 하는 것이 더 편하다.\n",
    "      * 로그 함수는 단조 증가 함수이기 때문에 로그 함수 최대화는 원래 함수 최대화 하는 문제와 동등하게 되며\n",
    "      * 수치 해석에서 로그 함수는 매우 큰수들의 곱을 더하기로 단순화 하기 때문에 성능을 높힐수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * 식(1.46), (1.53) 에서\n",
    "\n",
    "$$\\ln{p({\\bf x}\\mid \\mu, \\sigma^2)} = -\\dfrac{1}{2\\sigma^2}\\sum_{n=1}^{N}{(x_n-\\mu)^2}-\\dfrac{N}{2}\\ln\\sigma^2-\\dfrac{N}{2}\\ln(2\\pi) \\qquad{(1.54)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식(1.54) 에서 파라미터 $\\mu$ 관련하여 최대값이 나오려면, 식 1.54 를 $\\mu$ 에 관련 하여 편미분하여 극값이 나오는 $\\mu$를 선택하면 된다.\n",
    "       * 뒤 2개의 항은 $\\mu$ 하고 관계없어 미분하면 0 이되고, 처음항만 $\\mu$ 에 대해서 편미분 하면 되므로..\n",
    "       \n",
    "  $$\\mu_{ML}=\\dfrac{1}{N}\\sum_{n=1}^{N}x_n \\qquad{(1.55)}$$\n",
    "  \n",
    "       * 관측된 값 $\\left\\{x_n\\right\\}$ 의 평균으로 $simple\\,mean$ 이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 같은 방법으로 $\\sigma^2$ 에 관련하여 최대값을 구하려면 위와 같은 방법으로 하면 된다.\n",
    "       * $\\sigma^2$ 으로 편미분 하면, 마지막 항은 관계 없어 0이 되고, 두번째 항이 $\\dfrac{1}{\\sigma^2}$ 형태로 되어 이것을 풀면 다음과 같이 된다.\n",
    "$$\\sigma_{ML}^2=\\dfrac{1}{N}\\sum_{n=1}^{N}(x_n-\\mu_{ML})^2 \\qquad{(1.56)}$$\n",
    "       * $simple\\,mean$ $\\mu_{ML}$ 관련된 $simple\\,variance$ 라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식(1.54)를 $\\mu$ 와 $\\sigma^2$ 관련하여 결합된 최대화를 구하는 문제이다. 여기서는 각각을 분리하여 먼저 $\\mu$ 에 대해서 구하고 $\\sigma^2$ 에 대해서 구하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이장의 나머지, 그리고 계속해서 최대우도 접근방식의 한계점에 대해서 강조할 것이다.\n",
    "   * 여기서는 단변량 가우시안 분포에서 최대우도 파라미터 설정에 대한 해법에서 내용중에 문제점을 표시 할 것입니다.\n",
    "   * 특히 최대우도 접근 방법이 분포의 분산에 관련해서 저평가(bias) 하는것을 계속 보여 줄 것이다.\n",
    "   * 즉 variance 는 위 평균에서 bias 되어 있다.\n",
    "   * 이런것이 $bias$ 라고 불리는 현상에 대한 예 인데, 다항식 커브피팅 관련해서 over-fitting 문제하고 관계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 먼저 $\\mu_{ML}$ 과 $\\sigma_{ML}^2$ 이 데이터 셋트 $\\left\\{x_1,...,x_N\\right\\}$ 의 함수라는 것에 주목해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 분산과 평균의 기대값을 구하면 다음과 같다.\n",
    "   \n",
    "   $$\\mathbb E[\\mu_{ML}]=\\mu \\qquad{(1.57)}$$\n",
    "   \n",
    "   $$\\mathbb E[\\sigma_{ML}^2]=\\left(\\dfrac{N-1}{N}\\right)\\sigma^2 \\qquad{(1.58)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 여기서 보면 최대우도 추정치에 대한 평균은 $\\mu$ 이므로 맞는 것 처럼 보인다. 그러니 분산에서는 $\\dfrac{N - 1}{N}$ 만큼 적게 추정된다.\n",
    "   * 이 결과는 다음 그림에 잘 표현된다.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림 1-15\n",
    "   \n",
    "   <img src=\"./image/1-15bias.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 그림에 대한 설명\n",
    "      * 그림 1-15는 어떻게 분산이 bias 되는 지 보여준다\n",
    "      * 녹색선은 데이터가 생성된 진짜 가우시안 분포를 나타낸다.\n",
    "      * 3개의 빨강 곡선은 3개의 데이터 셋트로 식(1.55), 식(1.56) 최대우도추정 결과를 이용하여 fitting 한 가우스 분포를 나타낸다\n",
    "           * 각각은 푸른 점으로 나타난 2개의 점을 포함하고 있다.\n",
    "      * 3개의 데이터 세트에 대한 평균에 대한 평균은 실제 평균값에 가까워 진다.\n",
    "      * 3개의 분산에 대한 평균값에 대해서 평균을 구해도 실제 분산값에 가까워 지지 않는다.\n",
    "      * 10.1.3 절에서 베이지안 접근법을 사용할때 어떻게 자동적으로 이런 결과가 나온지는에 대해 보여 줄것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 (1.58) 에서,  분산 파라미터 에서는 다음의 unbiased 된것이다.\n",
    " \n",
    "$$\\tilde{\\sigma}^2=\\dfrac{N}{N-1}\\sigma_{ML}^2=\\dfrac{1}{N-1}\\sum_{n=1}^{N}(x_n-\\mu_{ML})^2 \\qquad{(1.59)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 데이터가 증가하면 최대우도에 bias 는 중요해지지 않는다.\n",
    "   * $N \\to \\infty$ 에서 분산에 대한 최대우도해는 원래 분산에 가까워 진다.\n",
    "   * 실제 문제에 있어서는 어떤 작은 N 에 대해서도, 이 bias 는 심각한 문제가 되지 않겠지만, 이책에서는 많은 파라미터를 가지고 있는데 더 복잡한 문제에 관심이 있을것이며, 이런 경우 최대우도와 관련 있는 bias 문제는 더욱 심각한 문제가 될 것이다.\n",
    "   * 실제 최대우도에 있는 문제는 커브피팅에서 만난 over-fitting 의 근본문제임을 볼것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 다시보는 커브 피팅(Curve fitting re-visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이전에 다항식을 이용하여 ㅇ$error\\,minimization$ 항으로 커브피팅문제를 어떻게 처리하는지 알아보아 왔다.\n",
    "   * 여기서 다시 커브피팅문제로 다시 돌아와서 확률적인 관점에서 살펴볼것이다.\n",
    "      * 에러 함수와 정규화(regularization) 에 대한 통찰\n",
    "      * 그리고 베이지안 처리 방법으로 안내"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 1-16 가우시안-에러\n",
    "\n",
    "<img src=\"./image/1-16gaussian-error.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 거브피팅 문제의 목적은 새로운 입력변수 $x$ 가 주어질때 타겟변수 $t$ 를 추정 할 수 있어야 한다.\n",
    "      * 입력데이터 ${\\bf x} = (x_1,...,x_N)^T$ 와 타켓값 ${\\bf t} = (t_1,...,t_N)^T$ 를 학습한 결과로서\n",
    "\n",
    "   * 확률분포를 이용하여 타켓 변수의 불확성을 표현 할 수 있다.\n",
    "   * 이런 목적으로, $x$ 에 관계하는 $t$ 값은 주어진 식(1.1) 에서 주어진 다항식 $y(x, {\\bf, w})$ 를 평균값으로 갖는 가우시안 분포를 가정한다.\n",
    "       * 즉 노이즈를 가우시안 분포로 고려하고 있다.\n",
    " \n",
    " $$p(t\\mid x, {\\bf w}, \\beta)= \\mathcal N(t \\mid y(x,{\\bf w}), \\beta^{-1}) \\qquad{(1.60)}$$\n",
    " \n",
    "      * 편위성을 위해서 precision 파라미터 $\\beta$ 를 분산의 역수로 정의 한다.\n",
    "      * 그림 1.16 참조 바람."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 학습테이터 $\\left\\{{\\bf x}, {\\bf t}\\right\\}$ 를 활용하여 최대우도 (maximum likelihood) 방법으로 미지수 ${\\bf w}$ 와 $\\beta$ 를 구한다.\n",
    "   * Generative model 이다.\n",
    "   * 데이타가 i.i.d 이라고 하면 식 (1.60) 은\n",
    "\n",
    "$$p({\\bf t} \\mid {\\bf x}, {\\bf w}, \\beta) = \\prod_{n=1}^{N}\\mathcal N(t_n \\mid y(x_n, {\\bf w}), \\beta^{-1}) \\qquad{(1.61)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이전에 설명하였듯이 log 함수로 최대우도를 구하는 것으로 문제를 시작할 수 있다.\n",
    "   \n",
    "$$\\ln p({\\bf t} \\mid {\\bf x}, {\\bf w}, \\beta) = -\\dfrac{\\beta}{2}\\sum_{n=1}^{N} \\left \\{y(x_n, {\\bf w})-t_n \\right\\}^{2} +\\dfrac{N}{2}\\ln\\beta-\\dfrac{N}{2}\\ln(2\\pi) \\qquad{(1.62)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 먼저 MLE 를 이용해 얻어지는 해를 ${\\bf w}_{ML}$ 이라고 한다. 이것은 식 (1.62)를 ${\\bf w}$ 과 관련해서 최대화 하면 구해진다.\n",
    "   * 이런 목적으로 1.62 의 마지막 2항은 소거한다. (${\\bf w}$ 화 관계없는 변수이다)\n",
    "   * log likelihood 함수의 scaling 을 양수로 바꾸어도 ${\\bf w}$ 에 대한 최대값의 위치는 변하지 않는다.\n",
    "   * $\\dfrac{\\beta}{2}$ 를 $\\dfrac{1}{2}$ 로 바꿀수도 있다.\n",
    "   * 따라서 최대값을 구하는 대신에 negative log likelihood 의 최소값을 구하는 문제로 생각을 해도 된다.\n",
    "   * 따라서 이문제는 ${\\bf w}$ 가 정해진 한, 식(1.2) 에 정의된 $sum-of-squares\\,error\\,function$ 을 최소화 하는 문제와 동등하다.\n",
    "   * sum-of-squres error function 이 노이즈의 가우시안 분포 가정으로 maximizing likekihood 하는 결론으로 나타난것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * MLE 를 이용하여 $\\beta$ (precision parameter) 도 같은  방식으로 구한다. 식 1.62 를 $\\beta$ 에 대해서 구해보면\n",
    "\n",
    "$$\\dfrac{1}{\\beta}=\\dfrac{1}{N}\\sum_{n=1}^{N}\\left\\{y(x_n, {\\bf w}_{ML})-t_n\\right\\}^2 \\qquad{(1.63)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 결정된 파라미터 ${\\bf w}$ 와 $\\beta$ 를 이용하면 새로운 값 x 에 관한 추정을 할 수 있게된다. \n",
    "   * 확률적 모델을 사용하므로 이런 접근은 예측분포(predictive distribution) 이라고 표현한다.\n",
    "       * 단순 추정 포인트 라기보다는 $t$ 상에서 확률적 분포이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 식 1.60 에서 파라미터를 MLE 변수로 바꾸면\n",
    "   \n",
    " $$p(t\\mid x, {\\bf w}_{ML}, \\beta_{ML})= \\mathcal N(t \\mid y(x,{\\bf w}_{ML}), \\beta_{ML}^{-1}) \\qquad{(1.61)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이지안 관점 (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베이지안 관점으로 한번 더 나가 보자\n",
    "   * 다항식 계수 ${\\bf w}$ 에 대한 사전 분포를 구해보자.\n",
    "   * 간단히 하기 위해서 가우시안 분포가 다음과 같은 형식으로 된다고 하자.\n",
    "   \n",
    " $$p({\\bf w}\\mid \\alpha)=\\mathcal N({\\bf w} \\mid 0, \\alpha^{-1}{\\bf I})=\\left(\\dfrac{\\alpha}{2\\pi}\\right)^{(M+1)/2}\\exp\\left\\{-\\dfrac{\\alpha}{2}{\\bf w}^T{\\bf w}\\right\\} \\qquad{(1.65)}$$\n",
    "      \n",
    "      * $\\alpha$ : 분포의 정확도 (precision)\n",
    "      * $M + 1$ : M 차 다항식 에서 ${\\bf w}$ 의 갯수\n",
    "      * $\\alpha$ 같은 변수는 모델 파라미터를 조정하는 것이기 때문에 $hyperparameters$ (초모스) 라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 베이즈 정리를 이용하여 ${\\bf w}$ 에 대한 사후분포는 다음과 같다.\n",
    "   \n",
    " $$p({\\bf w}\\mid {\\bf x}, {\\bf t}, \\alpha, \\beta) \\propto p({\\bf t}\\mid{\\bf x}, {\\bf w}, \\beta)p({\\bf w}\\mid\\alpha) \\qquad{(1.66)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 이제 주어진 데이터 에서 가장 가능성이 높은 ${\\bf w}$ 를 구하는 문제로 ${\\bf w}$ 를 구할수 있다. 즉 사후분포의 최대화를 하므로서.\n",
    "   * 이런 방법을 MAP(Maximum Posterior) 라고 한다.\n",
    "   * 식(1.66) (1.62) (1.65) 를 이용하면 사후분포의 최대화는 결국 다음식과 같이 되는데..\n",
    "\n",
    "$$\\dfrac{\\beta}{2}\\sum_{n=1}^{N}\\left\\{y(x_n, {\\bf w}-t_n)\\right\\}^2+\\dfrac{\\alpha}{2}{\\bf w}^T{\\bf w} \\qquad{(1.67)}$$\n",
    "\n",
    "   * 이것은 사후분포의 최대화는 초기 (1.4)식에서 보인 regularization parameter 를 도입헤서 regualrized sum-of-squares error function 을 최소화 하는 것과 동일 하게 된다.\n",
    "   \n",
    "       * reqularization parameter $\\lambda = \\dfrac{\\alpha}{\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 베이시안 커브 피팅 (Bayesian curve fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 바로 전절에서 사전분포 $p({\\bf w} \\mid {\\alpha})$ 를 도입하였으나 여전히 ${\\bf w}$ 를 추정 point 로 사용하므로, 베이지안 접근법이라고 할 수 없다.\n",
    "   * 베이지안 접근법으로 가려면 일관되게 확률의 곱과 합 법칙을 적용해야 하고, 간단하게 말해서 ${\\bf w}$ 의 모든 가능한 모든 값을 포함할 것을 요구한다. \n",
    "   * 그와 같은 ${\\bf w}$ 의 주변 확률분포를 사용하는 것이 패턴인식에서 베이지안 방법의 핵심이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 커브피팅 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 학습데이터 ${\\bf x}$ 와 ${\\bf t}$ 를 주어지고 나서 새로은 테스트 값 $x$ 를 주어질때 $t$ 를 예측하는 것이 목표이다.\n",
    "   * 따라서 추정분포  $p(t \\mid x, {\\bf x}, {\\bf t}) 를 평가 하기를 원한다.\n",
    "   * 이제 어떤 파라미터 $\\alpha$ 와 $\\beta$ 를 주어진다고 하고 이미 알고 있다고 하자.\n",
    "      * 마지막장 베이지안 설정에서 데이터로 부터 어떻게 파라미터를 추론할수 있는지 논의 할 것이다.\n",
    "   * 이 predictive distribution 은 다음과 같은 형태로 쓸수 있다.\n",
    "   \n",
    "   $$p(t \\mid x, {\\bf x}, {\\bf t})=\\int{p(t \\mid x, {\\bf w})\\,p({\\bf w} \\mid {\\bf x}, {\\bf t})}\\,d{\\bf w} \\qquad{(1.68)}$$\n",
    "      \n",
    "       * $p(t \\mid x, {\\bf w}) 는 식 1.60 에서 주어진다.\n",
    "       * $\\alpha$, $\\beta$ 는 식을 간단하게 하기위해서 무시 했다.\n",
    "       * $p({\\bf w} \\mid {\\bf x},{\\bf t}$ 가 사후 확률이다. 그리고 식 1.66 을 normaizing 하면 구해진다.\n",
    "       * 3.3 절에서 커브피팅 문제와 같은 예제를 사후확률에 가우시안 분포를 적용할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 3장에서 자세히 언급할 것이므로 결론만 받아들이자.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 1.68 적분은 수행하면 그결과 predictive distribution 은 다음과 같다.\n",
    "   \n",
    " $$p(t \\mid x, {\\bf x}, {\\bf t})=\\mathcal N(t \\mid m(x), s^2(x)) \\qquad{(1.69)}$$\n",
    " \n",
    "   * mean 과 variation 은 다음과 같다.\n",
    " \n",
    "$$m(x)=\\beta\\phi(x)^T{\\bf S}\\sum_{n=1}^{N}\\phi(x_n)t_n \\qquad{(1.70)}$$\n",
    "\n",
    "$$s^2(x) = \\beta^{-1} +  \\phi(x)^T {\\bf S} \\phi(x)\\qquad{(1.71)}$$\n",
    "\n",
    "   * matrix ${\\bf S}$ 는 다음과 같다\n",
    "\n",
    "$${\\bf S}^{-1}=\\alpha{\\bf I}+\\beta\\sum_{n=1}^{N}\\phi(x_n)\\phi(x_n)^T \\qquad{(1.72)}$$\n",
    "\n",
    "\n",
    "   * ${\\bf I}$ : unit matrix\n",
    "   * vector $\\phi(x)$ : $\\phi_i(x) = x^i$ for $i = 0,...,M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * 1.69 에서 분산 (variance) 와 mean 은 predictive distribution 에서 $x$ 의 함수이다.\n",
    "   * 1.71 첫 항은 $t$ 에 붙은 노이즈 때문에 나타나고 이미 식 1.64 에서 $\\beta_{ML}^{-1}$ 로 나타나 있다.\n",
    "   * 1.71 에서 두번째 항이 파라미터 ${\\bf w}$ 의 불확정 때문에 나타나니고 베이지안의 결과이다.\n",
    "   \n",
    "   * 그림 1.17 에 predictive distribution 에 대한 것이 설명되어 있다.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 1.17 \n",
    "\n",
    "<img src=\"./image/1-17predictive.png\" width=\"800\" height=\"300\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * M = 9 인 다항식에서 베이지안 방법으로 처리한 결과이다.\n",
    "   * $\\alpha = 5 \\times 10Y{-3}$ 이고 $\\beta = 11.1$ 이다.\n",
    "   * 녹색선이 원래 선이고 빨간선이 모델을 통해서 만든 근사선이다.\n",
    "   * 핑크색 주변이 표준편차 $\\pm{1}$ 을 나타낸다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
